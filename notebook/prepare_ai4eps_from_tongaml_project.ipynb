{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy.clients.filesystem.tsindex import Client\n",
    "from obspy import UTCDateTime\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "import obspy\n",
    "import h5py\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from absl import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13616\n"
     ]
    }
   ],
   "source": [
    "catalog_df=pd.read_csv(\"./data/TongaML_final_catalog.csv\")\n",
    "catalog_df[\"time\"]=pd.to_datetime(catalog_df[\"time\"])\n",
    "catalog_df=catalog_df.drop(columns=[\"horizontal uncertainty (km)\", \"vertical uncertainty (km)\", \"origin time uncertainty (s)\", \"largest azimuthal gap (degree)\", \"ISCid\"])\n",
    "catalog_df.rename(columns={\"latitude (degree)\":\"latitude\", \"longitude (degree)\":\"longitude\", \"depth (km)\":\"depth\"}, inplace=True)\n",
    "catalog_df.rename(columns={\"id\": \"EVENT_ID\", \"latitude\": \"ELAT\", \"longitude\": \"ELON\", \"depth\": \"EDEP\", \"time\": \"ORIGIN_TIME\"}, inplace=True)\n",
    "print(len(catalog_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>ELAT</th>\n",
       "      <th>ELON</th>\n",
       "      <th>EDEP</th>\n",
       "      <th>ORIGIN_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>-24.0547</td>\n",
       "      <td>-178.7527</td>\n",
       "      <td>581.54</td>\n",
       "      <td>2010-09-05 06:20:43.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>-22.9965</td>\n",
       "      <td>-175.6553</td>\n",
       "      <td>85.23</td>\n",
       "      <td>2010-02-03 07:50:12.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>-23.1014</td>\n",
       "      <td>-178.6428</td>\n",
       "      <td>554.76</td>\n",
       "      <td>2010-07-21 13:36:11.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>-21.8630</td>\n",
       "      <td>-175.5906</td>\n",
       "      <td>140.71</td>\n",
       "      <td>2010-02-07 15:23:13.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95</td>\n",
       "      <td>-20.3652</td>\n",
       "      <td>-177.1233</td>\n",
       "      <td>446.39</td>\n",
       "      <td>2010-04-16 07:59:40.671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EVENT_ID     ELAT      ELON    EDEP             ORIGIN_TIME\n",
       "0        49 -24.0547 -178.7527  581.54 2010-09-05 06:20:43.697\n",
       "1        59 -22.9965 -175.6553   85.23 2010-02-03 07:50:12.697\n",
       "2        64 -23.1014 -178.6428  554.76 2010-07-21 13:36:11.900\n",
       "3        78 -21.8630 -175.5906  140.71 2010-02-07 15:23:13.122\n",
       "4        95 -20.3652 -177.1233  446.39 2010-04-16 07:59:40.671"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417570\n"
     ]
    }
   ],
   "source": [
    "picks_df=pd.read_csv(\"./data/TongaML_final_picks.csv\")\n",
    "picks_df[\"time\"]=pd.to_datetime(picks_df[\"time\"])\n",
    "picks_df[\"net\"]=picks_df[\"id\"].str.split(\".\").str[0]\n",
    "picks_df[\"sta\"]=picks_df[\"id\"].str.split(\".\").str[1]\n",
    "picks_df.drop(columns=[\"id\"],inplace=True)\n",
    "# time\ttype\tevent_index\tnet\tsta\n",
    "picks_df.rename(columns={\"event_index\": \"EVENT_ID\", \"net\": \"NETWORK\", \"sta\": \"STATION\"}, inplace=True)\n",
    "print(len(picks_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338812\n",
      "78758\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>NETWORK</th>\n",
       "      <th>STATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-11-04 20:43:53.969900</td>\n",
       "      <td>P</td>\n",
       "      <td>98879</td>\n",
       "      <td>II</td>\n",
       "      <td>MSVF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-11-06 16:32:12.919900</td>\n",
       "      <td>P</td>\n",
       "      <td>79255</td>\n",
       "      <td>II</td>\n",
       "      <td>MSVF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-11-08 16:39:36.679900</td>\n",
       "      <td>P</td>\n",
       "      <td>98419</td>\n",
       "      <td>II</td>\n",
       "      <td>MSVF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-11-10 08:05:07.049900</td>\n",
       "      <td>P</td>\n",
       "      <td>71320</td>\n",
       "      <td>II</td>\n",
       "      <td>MSVF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-11-10 08:17:57.599900</td>\n",
       "      <td>P</td>\n",
       "      <td>14608</td>\n",
       "      <td>II</td>\n",
       "      <td>MSVF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time type  EVENT_ID NETWORK STATION\n",
       "0 2009-11-04 20:43:53.969900    P     98879      II    MSVF\n",
       "1 2009-11-06 16:32:12.919900    P     79255      II    MSVF\n",
       "2 2009-11-08 16:39:36.679900    P     98419      II    MSVF\n",
       "3 2009-11-10 08:05:07.049900    P     71320      II    MSVF\n",
       "4 2009-11-10 08:17:57.599900    P     14608      II    MSVF"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(picks_df[picks_df[\"type\"]==\"P\"]))\n",
    "print(len(picks_df[picks_df[\"type\"]==\"S\"]))\n",
    "picks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_and_filter_dataframes(catalog_df, picks_df):\n",
    "    \"\"\"\n",
    "    Joins catalog_df and picks_df, filters and selects specific columns,\n",
    "    and identifies problematic (event_index, station) combinations.\n",
    "\n",
    "    Args:\n",
    "        catalog_df: DataFrame with EVENT_ID, ELAT, ELON, EDEP, ORIGIN_TIME.\n",
    "        picks_df: DataFrame with time, type, EVENT_INDEX, NETWORK, STATION.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - result_df: The joined and filtered DataFrame.\n",
    "        - problem_set: A set of problematic (event_index, station) combinations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create PTIME and STIME columns in picks_df\n",
    "    picks_df['PTIME'] = picks_df.apply(lambda row: row['time'] if row['type'] == 'P' else None, axis=1)\n",
    "    picks_df['STIME'] = picks_df.apply(lambda row: row['time'] if row['type'] == 'S' else None, axis=1)\n",
    "\n",
    "    # Group by EVENT_ID and STATION to find problematic combinations\n",
    "    problem_set = set()\n",
    "    \n",
    "    def check_problems(group):\n",
    "      p_count = group['PTIME'].notna().sum()\n",
    "      s_count = group['STIME'].notna().sum()\n",
    "      \n",
    "      if p_count >= 2 or s_count >= 2 or (s_count > 0 and p_count == 0):\n",
    "        problem_set.add((group['EVENT_ID'].iloc[0], group['STATION'].iloc[0]))\n",
    "\n",
    "    picks_df.groupby(['EVENT_ID', 'STATION']).apply(check_problems)\n",
    "    \n",
    "    \n",
    "    # Merge DataFrames with a left join on EVENT_ID, STATION and NETWORK\n",
    "    # Use inner join to match the unique event in catalog_df and station/network in picks_df\n",
    "    \n",
    "    picks_df = picks_df.groupby([\"EVENT_ID\",\"STATION\",\"NETWORK\"]).agg(PTIME = (\"PTIME\", \"min\"), STIME = (\"STIME\", \"min\")).reset_index()\n",
    "\n",
    "    merged_df = pd.merge(catalog_df, picks_df, on='EVENT_ID', how='left')\n",
    "\n",
    "    # Select desired columns and rename them if needed\n",
    "    result_df = merged_df[['EVENT_ID', 'ORIGIN_TIME', 'STATION', 'NETWORK', 'ELON', 'ELAT', 'EDEP', 'PTIME', 'STIME']]\n",
    "    \n",
    "    # Add SLON and SLAT (assuming they are needed later - they are not present in your sample dataframes)\n",
    "    # You would likely need to join with another dataframe containing station locations here\n",
    "    # For example, if you have a 'stations_df' with columns 'STATION', 'NETWORK', 'SLON', 'SLAT':\n",
    "    # result_df = pd.merge(result_df, stations_df[['STATION', 'NETWORK', 'SLON', 'SLAT']], on=['STATION', 'NETWORK'], how='left')\n",
    "    # For now, let's add placeholder columns\n",
    "    result_df['SLON'] = None  # Placeholder\n",
    "    result_df['SLAT'] = None  # Placeholder\n",
    "    \n",
    "    return result_df, problem_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "with open('./data/stations.json') as f:\n",
    "    stations_raw = json.load(f)\n",
    "\n",
    "stations={}\n",
    "for key in stations_raw:\n",
    "    sta=key.split('.')[1]\n",
    "    stations[sta]={\n",
    "        \"STATION\":sta,\n",
    "        \"latitude\":stations_raw[key]['latitude'],\n",
    "        \"longitude\":stations_raw[key]['longitude'],\n",
    "        \"elevation_m\":stations_raw[key]['elevation_m'],\n",
    "        \"NETWORK\":key.split('.')[0],\n",
    "    }\n",
    "stations_df=pd.DataFrame.from_dict(stations,orient=\"index\")\n",
    "print(len(stations_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation_m</th>\n",
       "      <th>NETWORK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A01</th>\n",
       "      <td>A01</td>\n",
       "      <td>-21.533899</td>\n",
       "      <td>-175.623505</td>\n",
       "      <td>-1059.0</td>\n",
       "      <td>YL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A02W</th>\n",
       "      <td>A02W</td>\n",
       "      <td>-21.489500</td>\n",
       "      <td>-175.789993</td>\n",
       "      <td>-2015.0</td>\n",
       "      <td>YL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A03</th>\n",
       "      <td>A03</td>\n",
       "      <td>-21.443100</td>\n",
       "      <td>-175.896103</td>\n",
       "      <td>-1955.0</td>\n",
       "      <td>YL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A05</th>\n",
       "      <td>A05</td>\n",
       "      <td>-21.352100</td>\n",
       "      <td>-176.171005</td>\n",
       "      <td>-2368.0</td>\n",
       "      <td>YL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A06W</th>\n",
       "      <td>A06W</td>\n",
       "      <td>-21.303699</td>\n",
       "      <td>-176.321594</td>\n",
       "      <td>-2137.0</td>\n",
       "      <td>YL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     STATION   latitude   longitude  elevation_m NETWORK\n",
       "A01      A01 -21.533899 -175.623505      -1059.0      YL\n",
       "A02W    A02W -21.489500 -175.789993      -2015.0      YL\n",
       "A03      A03 -21.443100 -175.896103      -1955.0      YL\n",
       "A05      A05 -21.352100 -176.171005      -2368.0      YL\n",
       "A06W    A06W -21.303699 -176.321594      -2137.0      YL"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347829\n",
      "338812\n",
      "78758\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>ORIGIN_TIME</th>\n",
       "      <th>STATION</th>\n",
       "      <th>NETWORK</th>\n",
       "      <th>ELON</th>\n",
       "      <th>ELAT</th>\n",
       "      <th>EDEP</th>\n",
       "      <th>PTIME</th>\n",
       "      <th>STIME</th>\n",
       "      <th>SLON</th>\n",
       "      <th>SLAT</th>\n",
       "      <th>SEVL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>2010-09-05 06:20:43.697</td>\n",
       "      <td>A01</td>\n",
       "      <td>YL</td>\n",
       "      <td>-178.7527</td>\n",
       "      <td>-24.0547</td>\n",
       "      <td>581.54</td>\n",
       "      <td>2010-09-05 06:22:03.761000</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-175.623505</td>\n",
       "      <td>-21.533899</td>\n",
       "      <td>-1059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>2010-09-05 06:20:43.697</td>\n",
       "      <td>A02W</td>\n",
       "      <td>YL</td>\n",
       "      <td>-178.7527</td>\n",
       "      <td>-24.0547</td>\n",
       "      <td>581.54</td>\n",
       "      <td>2010-09-05 06:22:03.603700</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-175.789993</td>\n",
       "      <td>-21.489500</td>\n",
       "      <td>-2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>2010-09-05 06:20:43.697</td>\n",
       "      <td>A03</td>\n",
       "      <td>YL</td>\n",
       "      <td>-178.7527</td>\n",
       "      <td>-24.0547</td>\n",
       "      <td>581.54</td>\n",
       "      <td>2010-09-05 06:22:03.945000</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-175.896103</td>\n",
       "      <td>-21.443100</td>\n",
       "      <td>-1955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>2010-09-05 06:20:43.697</td>\n",
       "      <td>A14W</td>\n",
       "      <td>YL</td>\n",
       "      <td>-178.7527</td>\n",
       "      <td>-24.0547</td>\n",
       "      <td>581.54</td>\n",
       "      <td>2010-09-05 06:22:00.615100</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-178.155304</td>\n",
       "      <td>-20.665800</td>\n",
       "      <td>-884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>2010-09-05 06:20:43.697</td>\n",
       "      <td>B03</td>\n",
       "      <td>YL</td>\n",
       "      <td>-178.7527</td>\n",
       "      <td>-24.0547</td>\n",
       "      <td>581.54</td>\n",
       "      <td>2010-09-05 06:22:15.740000</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-175.385498</td>\n",
       "      <td>-19.941401</td>\n",
       "      <td>-2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347814</th>\n",
       "      <td>109051</td>\n",
       "      <td>2010-06-08 01:00:19.543</td>\n",
       "      <td>C13</td>\n",
       "      <td>YL</td>\n",
       "      <td>-166.0604</td>\n",
       "      <td>-7.0963</td>\n",
       "      <td>136.66</td>\n",
       "      <td>2010-06-08 01:12:21.913000</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-176.358093</td>\n",
       "      <td>-20.453600</td>\n",
       "      <td>-2280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347815</th>\n",
       "      <td>109051</td>\n",
       "      <td>2010-06-08 01:00:19.543</td>\n",
       "      <td>C15</td>\n",
       "      <td>YL</td>\n",
       "      <td>-166.0604</td>\n",
       "      <td>-7.0963</td>\n",
       "      <td>136.66</td>\n",
       "      <td>2010-06-08 01:03:03.296000</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-176.715195</td>\n",
       "      <td>-20.048000</td>\n",
       "      <td>-2512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347816</th>\n",
       "      <td>109051</td>\n",
       "      <td>2010-06-08 01:00:19.543</td>\n",
       "      <td>C16W</td>\n",
       "      <td>YL</td>\n",
       "      <td>-166.0604</td>\n",
       "      <td>-7.0963</td>\n",
       "      <td>136.66</td>\n",
       "      <td>2010-06-08 01:07:52.477600</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-176.828903</td>\n",
       "      <td>-20.570400</td>\n",
       "      <td>-2213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347817</th>\n",
       "      <td>109051</td>\n",
       "      <td>2010-06-08 01:00:19.543</td>\n",
       "      <td>F02W</td>\n",
       "      <td>YL</td>\n",
       "      <td>-166.0604</td>\n",
       "      <td>-7.0963</td>\n",
       "      <td>136.66</td>\n",
       "      <td>2010-06-08 01:06:16.150201</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-174.438797</td>\n",
       "      <td>-21.349199</td>\n",
       "      <td>-2602.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347818</th>\n",
       "      <td>109051</td>\n",
       "      <td>2010-06-08 01:00:19.543</td>\n",
       "      <td>N01W</td>\n",
       "      <td>YL</td>\n",
       "      <td>-166.0604</td>\n",
       "      <td>-7.0963</td>\n",
       "      <td>136.66</td>\n",
       "      <td>2010-06-08 01:02:12.745600</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-175.485504</td>\n",
       "      <td>-19.024300</td>\n",
       "      <td>-2325.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>347819 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        EVENT_ID             ORIGIN_TIME STATION NETWORK      ELON     ELAT  \\\n",
       "0             49 2010-09-05 06:20:43.697     A01      YL -178.7527 -24.0547   \n",
       "1             49 2010-09-05 06:20:43.697    A02W      YL -178.7527 -24.0547   \n",
       "2             49 2010-09-05 06:20:43.697     A03      YL -178.7527 -24.0547   \n",
       "3             49 2010-09-05 06:20:43.697    A14W      YL -178.7527 -24.0547   \n",
       "4             49 2010-09-05 06:20:43.697     B03      YL -178.7527 -24.0547   \n",
       "...          ...                     ...     ...     ...       ...      ...   \n",
       "347814    109051 2010-06-08 01:00:19.543     C13      YL -166.0604  -7.0963   \n",
       "347815    109051 2010-06-08 01:00:19.543     C15      YL -166.0604  -7.0963   \n",
       "347816    109051 2010-06-08 01:00:19.543    C16W      YL -166.0604  -7.0963   \n",
       "347817    109051 2010-06-08 01:00:19.543    F02W      YL -166.0604  -7.0963   \n",
       "347818    109051 2010-06-08 01:00:19.543    N01W      YL -166.0604  -7.0963   \n",
       "\n",
       "          EDEP                      PTIME STIME        SLON       SLAT    SEVL  \n",
       "0       581.54 2010-09-05 06:22:03.761000   NaT -175.623505 -21.533899 -1059.0  \n",
       "1       581.54 2010-09-05 06:22:03.603700   NaT -175.789993 -21.489500 -2015.0  \n",
       "2       581.54 2010-09-05 06:22:03.945000   NaT -175.896103 -21.443100 -1955.0  \n",
       "3       581.54 2010-09-05 06:22:00.615100   NaT -178.155304 -20.665800  -884.0  \n",
       "4       581.54 2010-09-05 06:22:15.740000   NaT -175.385498 -19.941401 -2015.0  \n",
       "...        ...                        ...   ...         ...        ...     ...  \n",
       "347814  136.66 2010-06-08 01:12:21.913000   NaT -176.358093 -20.453600 -2280.0  \n",
       "347815  136.66 2010-06-08 01:03:03.296000   NaT -176.715195 -20.048000 -2512.0  \n",
       "347816  136.66 2010-06-08 01:07:52.477600   NaT -176.828903 -20.570400 -2213.0  \n",
       "347817  136.66 2010-06-08 01:06:16.150201   NaT -174.438797 -21.349199 -2602.0  \n",
       "347818  136.66 2010-06-08 01:02:12.745600   NaT -175.485504 -19.024300 -2325.0  \n",
       "\n",
       "[347819 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Prepare picks_df\n",
    "picks_pivot = picks_df.pivot_table(\n",
    "    index=['EVENT_ID', 'NETWORK', 'STATION'],\n",
    "    columns='type',\n",
    "    values='time',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "picks_pivot = picks_pivot.rename(columns={'P': 'PTIME', 'S': 'STIME'})\n",
    "\n",
    "# 2. Merge with stations_df to get station coordinates and SEVL.\n",
    "picks_pivot = picks_pivot.merge(stations_df, on=['STATION', 'NETWORK'], how='left')\n",
    "picks_pivot = picks_pivot.rename(\n",
    "    columns={\n",
    "        'latitude': 'SLAT',\n",
    "        'longitude': 'SLON',\n",
    "        'elevation_m': 'SEVL'\n",
    "    }\n",
    ")\n",
    "\n",
    "# 3. Merge with catalog_df to get event details\n",
    "merged_df = catalog_df.merge(picks_pivot, on='EVENT_ID', how='left')\n",
    "\n",
    "# 4. Select and Reorder Columns\n",
    "final_df = merged_df[[\n",
    "    'EVENT_ID', 'ORIGIN_TIME', 'STATION', 'NETWORK', 'ELON', 'ELAT',\n",
    "    'EDEP', 'PTIME', 'STIME', 'SLON', 'SLAT', 'SEVL'\n",
    "]]\n",
    "\n",
    "print(len(final_df))\n",
    "print(len(final_df.dropna(subset=[\"PTIME\"])))\n",
    "print(len(final_df.dropna(subset=[\"STIME\"])))\n",
    "final_df.head(n=-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338812\n"
     ]
    }
   ],
   "source": [
    "# only select final_df where PTIME exists\n",
    "final_df=final_df.dropna(subset=[\"PTIME\"])\n",
    "print(len(final_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"./result/TongaML_final_catalog_picks.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=Client(\"/mnt/scratch/xiziyi/database/timeseries.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    problems = []\n",
    "    start = UTCDateTime(row[\"PTIME\"])-240\n",
    "    end = UTCDateTime(row[\"PTIME\"])+360\n",
    "    net, sta, evid = row[\"NETWORK\"], row[\"STATION\"], row[\"EVENT_ID\"]\n",
    "    res = np.zeros((3,24000), dtype=np.float32)\n",
    "    use_12z = False\n",
    "    try:\n",
    "        tr_z = client.get_waveforms(net, sta, \"*\", \"*Z\", start, end)[0]\n",
    "        st_1 = client.get_waveforms(net, sta, \"*\", \"*N\", start, end)\n",
    "        if len(st_1) == 0:\n",
    "            tr_1 = client.get_waveforms(net, sta, \"*\", \"*1\", start, end)[0]\n",
    "            use_12z = True\n",
    "        else:\n",
    "            tr_1 = st_1[0]\n",
    "        st_2 = client.get_waveforms(net, sta, \"*\", \"*E\", start, end)\n",
    "        if len(st_2) == 0:\n",
    "            tr_2 = client.get_waveforms(net, sta, \"*\", \"*2\", start, end)[0]\n",
    "            use_12z = True\n",
    "        else:\n",
    "            tr_2 = st_2[0]\n",
    "        \n",
    "        # prepare output\n",
    "        d1=tr_1.data[:24000]\n",
    "        d2=tr_2.data[:24000]\n",
    "        dz=tr_z.data[:24000]\n",
    "        res[0,:len(d1)]=d1[:]\n",
    "        res[1,:len(d2)]=d2[:]\n",
    "        res[2,:len(dz)]=dz[:]\n",
    "\n",
    "        attrs = {\n",
    "            \"station\": row[\"STATION\"],\n",
    "            \"phase_type\" :[],\n",
    "            \"phase_index\": [],\n",
    "            \"component\": [\"1\", \"2\", \"Z\"] if use_12z else [\"N\", \"E\", \"Z\"],\n",
    "        }\n",
    "\n",
    "        # if PTIME exists, add P phase type and index\n",
    "        if not pd.isna(row[\"PTIME\"]):\n",
    "            attrs[\"phase_type\"].append(\"P\")\n",
    "            attrs[\"phase_index\"].append(int((UTCDateTime(row[\"PTIME\"])-start)*40))\n",
    "        # if STIME exists, add S phase type and index\n",
    "        if not pd.isna(row[\"STIME\"]):\n",
    "            attrs[\"phase_type\"].append(\"S\")\n",
    "            attrs[\"phase_index\"].append(int((UTCDateTime(row[\"STIME\"])-start)*40))\n",
    "        return str(row[\"EVENT_ID\"]), res, attrs, []\n",
    "\n",
    "    except Exception as e:\n",
    "        problems.append((net, sta, evid))\n",
    "        return None, None, None, problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_hdf5(event_id, data, attrs, h5py_file):\n",
    "    if event_id not in h5py_file:\n",
    "        h5py_file.create_group(event_id)\n",
    "    group = h5py_file[event_id]\n",
    "    wave = group.create_dataset(attrs[\"station\"], data=data, compression=\"gzip\", compression_opts=9)\n",
    "    for key, value in attrs.items():\n",
    "        wave.attrs[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/338812 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Submitting: 100%|██████████| 338812/338812 [00:41<00:00, 8128.03it/s] \n",
      "Processing: 100%|██████████| 338812/338812 [1:07:41<00:00, 83.42it/s] \n"
     ]
    }
   ],
   "source": [
    "process_df = final_df.copy()\n",
    "num_cores = 50\n",
    "h5py_file = h5py.File(\"./data_scratch/concurrency_files/TongaML_final.h5\", \"w\")\n",
    "submitting_bar = tqdm(total=len(process_df), desc=\"Submitting\", position=0)\n",
    "progress_bar = tqdm(total=len(process_df), desc=\"Processing\", position=0)\n",
    "with ProcessPoolExecutor(max_workers=num_cores) as executor:\n",
    "    futures = []\n",
    "    total_rows = len(process_df)\n",
    "    for i in range(0, total_rows, num_cores):\n",
    "        for index in range(num_cores):\n",
    "            if i + index < total_rows:\n",
    "                row = process_df.iloc[i + index]\n",
    "                futures.append(executor.submit(process_row, row))\n",
    "                submitting_bar.update(1)\n",
    "    submitting_bar.close()\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result[0] is not None:\n",
    "            save_to_hdf5(result[0], result[1], result[2], h5py_file)\n",
    "        progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "h5py_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
